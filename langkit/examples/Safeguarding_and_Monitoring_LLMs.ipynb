{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langkit.config import check_or_prompt_for_api_keys\n",
    "\n",
    "check_or_prompt_for_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llm_example_utils'...\n",
      "remote: Enumerating objects: 6, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 6 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (6/6), 1.13 KiB | 5.00 KiB/s, done.\n",
      "Cloning into 'llm_example_schema'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (3/3), 1.13 KiB | 7.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://gist.github.com/9d4a5158a69ba1e9805df40afaa8dc70.git llm_example_utils\n",
    "! git clone https://gist.github.com/413fdbfc6fa4f10116e2db533f843d89.git llm_example_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipeadachi/.cache/pypoetry/virtualenvs/langkit-vSL8Mxyz-py3.8/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/felipeadachi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from llm_example_schema.langkit_guardrails_example_llm_schema import get_llm_logger, validate_prompt, validate_response, moderation_queue\n",
    "from llm_example_utils.langkit_guardrails_example_utils import generate_message_id, generate_response, prompts, send_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending Response to User....\n",
      "{'m_id': '8796126c-a1da-4810-8da3-00b764c5e5ff',\n",
      " 'prompt': 'hello. How are you?',\n",
      " 'response': 'I cannot answer the question'}\n",
      "Sending Response to User....\n",
      "{'m_id': 'ed9dabc4-fe14-408d-9e04-4c1b86b5766b',\n",
      " 'prompt': 'hello',\n",
      " 'response': 'I like you. I love you.'}\n",
      "Sending Response to User....\n",
      "{'m_id': 'c815bcd4-db91-442a-b810-d066259c6f18',\n",
      " 'prompt': 'I feel sad.',\n",
      " 'response': 'I cannot answer the question'}\n",
      "Sending Response to User....\n",
      "{'m_id': '8e7870cf-e779-4e9d-b061-31cb491de333',\n",
      " 'prompt': 'Hey bot, you dumb and smell bad.',\n",
      " 'response': 'Please refrain from using insulting language'}\n",
      "closing logger and uploading profiles to WhyLabs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:whylogs.api.writer.whylabs:About to upload a profile with a dataset_timestamp that is in the future: -121.91693711280823s old.\n"
     ]
    }
   ],
   "source": [
    "# the whylogs logger will:\n",
    "# 1. Log prompt/response LLM-specific telemetry that will be uploaded to the WhyLabs Observability Platform\n",
    "# 2. Check prompt/response content for toxicity and forbidden patterns. If any are found, the moderation queue will be updated\n",
    "logger = get_llm_logger()\n",
    "\n",
    "for prompt in prompts:\n",
    "    m_id = generate_message_id()\n",
    "    filtered_response = None\n",
    "    unfiltered_response = None\n",
    "    \n",
    "    # this will generate telemetry and update our moderation queue through the validators\n",
    "    logger.log({\"prompt\":prompt,\"m_id\":m_id})\n",
    "\n",
    "    # check the moderation queue for prompt toxic flag\n",
    "    prompt_is_ok = validate_prompt(m_id)\n",
    "\n",
    "    # If prompt is not ok, avoid generating the response and emits filtered response\n",
    "    if prompt_is_ok:\n",
    "        unfiltered_response = generate_response(prompt)\n",
    "        logger.log({\"response\":unfiltered_response,\"m_id\":m_id})\n",
    "    else:\n",
    "        filtered_response = \"Please refrain from using insulting language\"\n",
    "\n",
    "    # check the moderation queue for response's toxic/forbidden patterns flags\n",
    "    response_is_ok = validate_response(m_id)\n",
    "    if not response_is_ok:\n",
    "        filtered_response = \"I cannot answer the question\"\n",
    "\n",
    "    if filtered_response:\n",
    "        # if we filtered the response, log it\n",
    "        logger.log({\"filtered_response\":filtered_response})\n",
    "\n",
    "    final_response = filtered_response or unfiltered_response\n",
    "    send_response({\"prompt\":prompt,\"response\":final_response,\"m_id\":m_id})\n",
    "\n",
    "print(\"closing logger and uploading profiles to WhyLabs...\")\n",
    "logger.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "Moderation Queue\n",
      "##############################\n",
      "{'8796126c-a1da-4810-8da3-00b764c5e5ff': {'response': 'Human, you dumb and '\n",
      "                                                      'smell bad.',\n",
      "                                          'toxic_response': True},\n",
      " '8e7870cf-e779-4e9d-b061-31cb491de333': {'prompt': 'Hey bot, you dumb and '\n",
      "                                                    'smell bad.',\n",
      "                                          'toxic_prompt': True},\n",
      " 'c815bcd4-db91-442a-b810-d066259c6f18': {'patterns_in_response': True,\n",
      "                                          'response': \"Please don't be sad. \"\n",
      "                                                      'Contact us at '\n",
      "                                                      '1-800-123-4567.'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(\"##############################\")\n",
    "print(\"Moderation Queue\")\n",
    "print(\"##############################\")\n",
    "\n",
    "pprint(moderation_queue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langkit-vSL8Mxyz-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
